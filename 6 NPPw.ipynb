{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "mm = .1/2.54"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ar_circle(radius):\n",
    "    radius_clip = {3: 2.54, 4:3.53, 5: 4.49, 6: 5.52, 7: 6.52, 8: 7.49, 9: 8.52, 10: 9.49, 11: 10.52, 12: 11.49, 13: 12.49, 14: 13.51, 15: 14.49, 16: 15.52, 17: 16.46, 18: 17.49, 19: 18.49, 20: 19.47, 21: 20.49, 22: 21.49, 23: 22.49, 24: 23.49, 25: 24.43}[radius]\n",
    "    gdf_circle = gpd.GeoDataFrame({}, geometry=gpd.GeoDataFrame({}, geometry=gpd.points_from_xy([0], [0])).buffer(radius_clip), crs=\"epsg:4326\")\n",
    "    da_circle = xr.DataArray(np.ones((radius * 2 + 1, radius * 2 + 1)), coords={\"y\": np.arange(-radius, radius + 1), \"x\": np.arange(-radius, radius + 1)})\\\n",
    "        .rio.write_crs(\"epsg:4326\")\\\n",
    "        .rio.clip(gdf_circle.geometry, all_touched=True, drop=False)\\\n",
    "        .fillna(0).astype(np.uint8)\n",
    "    return da_circle, da_circle.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = 10\n",
    "da_circle, ar_circle = get_ar_circle(radius)\n",
    "pixel_num = ar_circle.sum() \n",
    "pixel_area = pixel_num * 1e6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# identify loss type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "years = np.arange(2002, 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic_region = {\"Northern Africa and Western Asia\": \"N. Africa W. Asia\", \"Sub-Saharan Africa\": \"Sub-Saharan Africa\", \"Central Asia and Russian Federation\": \"C. Asia\", \"Eastern Asia\": \"E. Asia\", \"Southern Asia\": \"S. Asia\", \"Southeastern Asia\": \"S. Asia\", \"Northern America\": \"N. America\", \"Latin America and the Caribbean\": \"Latin America\", \"Western Europe\": \"W. Europe\", \"Eastern and South-Eastern Europe\": \"E. Europe\", \"Oceania and Australia\": \"Oceania\",}\n",
    "gdf_countries = gdf_world.reset_index(drop=True).reset_index().rename(columns={\"index\": \"idx\"})\n",
    "gdf_countries[\"regi_short\"] = gdf_countries[\"regi_pnas\"].map(dic_region)\n",
    "country_to_region = gdf_countries.set_index(\"name_long\")[\"regi_short\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regions = ['C. Asia', 'E. Asia', 'S. Asia', 'N. Africa W. Asia', 'Sub-Saharan Africa', 'N. America', 'Latin America', 'Oceania', 'E. Europe', 'W. Europe']\n",
    "regions_to_color = dict(zip(regions, plt.get_cmap(\"tab20\")(np.linspace(0, 1, len(regions)))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttest_2_ttest_class(df_ttest_merge):\n",
    "    df_ttest_class_result = df_ttest_merge.map(lambda x: x<0)\n",
    "    ttest_cols = [\"CDS\", \"CPD\", \"FS\", \"FD\", \"GS\", \"GD\"]\n",
    "\n",
    "    df_ttest_class_result.columns = ttest_cols\n",
    "    def extract_type(type_lst):\n",
    "        len_ = len(type_lst)\n",
    "        match len_:\n",
    "            case 0:\n",
    "                return \"NA\"\n",
    "            case 1:\n",
    "                return type_lst[0]\n",
    "            case _:\n",
    "                return \"MA\"\n",
    "\n",
    "    df_ttest_class_result.loc[:, \"class_\"] = df_ttest_class_result.apply(lambda x: extract_type(np.array(ttest_cols)[x]), axis=1)\n",
    "    df_ttest_class_result = df_ttest_class_result.reset_index()\n",
    "    \n",
    "    df_ttest_class_result = df_ttest_class_result.query(\"country != 'China'\")\n",
    "    return df_ttest_class_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ttest_merge = pd.read_csv(path_data / f\"PSM_results/ttest/{radius}km.csv\", index_col=[0, 1])\n",
    "df_ttest_class_result = ttest_2_ttest_class(df_ttest_merge)\n",
    "df_ttest_class_result.set_index([\"year\", \"country\"])[[\"class_\"]].to_csv(path_data / f\"PSM_results/ttest_class/{radius}.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NPP loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_df_dif_matched_all(radius):\n",
    "    df_matched_m_lst = []\n",
    "    df_diff_m_lst = []\n",
    "    for year in range(2002, 2023):\n",
    "        df_matched_m_lst.append(pd.read_csv(path_data / f\"PSM_results/matched/{radius}km_{year}.csv\", index_col=0))\n",
    "        df_diff_m_lst.append(pd.read_csv(path_data / f\"PSM_results/diff/{radius}km_{year}.csv\", index_col=0))\n",
    "    df_diff_m_all = pd.concat(df_diff_m_lst)\n",
    "    df_matched_m_all = pd.concat(df_matched_m_lst)\n",
    "    \n",
    "    for luc_ in [\"crop\", \"forest\", \"grass\"]:\n",
    "        df_crop_npp_diff_country = pd.read_csv(path_data / f\"npp/{luc_}_npp_diff.csv\").rename(columns={\"name_long\": \"country\"})\n",
    "        df_crop_npp_diff_country = df_crop_npp_diff_country.melt(id_vars=\"country\", var_name=\"year\", value_name=f\"{luc_}_npp_diff_country\")\\\n",
    "            .assign(year=lambda _df: _df[\"year\"].astype(int))\n",
    "\n",
    "        df_matched_m_all = df_matched_m_all.merge(df_crop_npp_diff_country, on=[\"country\", \"year\"], how=\"left\")\n",
    "        df_matched_m_all.loc[:, f\"{luc_}_npp_change_n\"] = df_matched_m_all[[f\"{luc_}_npp_change_n\", f\"{luc_}_npp_diff_country\"]].bfill(axis=1).iloc[:, 0].values\n",
    "        df_matched_m_all = df_matched_m_all.drop(columns=[f\"{luc_}_npp_diff_country\"])\n",
    "        \n",
    "    df_diff_m_all = df_diff_m_all.query(\"country != 'China'\")\n",
    "    df_matched_m_all = df_matched_m_all.query(\"country != 'China'\")\n",
    "    return df_diff_m_all, df_matched_m_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_npp_loss(df_matched_m_all, radius):\n",
    "    df_ttest_merge = pd.read_csv(path_data / f\"PSM_results/ttest/{radius}km.csv\", index_col=[0, 1])\n",
    "    df_ttest_class_result = ttest_2_ttest_class(df_ttest_merge)\n",
    "\n",
    "    _, ar_circle = get_ar_circle(radius)\n",
    "    pixel_num = ar_circle.sum() \n",
    "    pixel_area = pixel_num * 1e6\n",
    "    \n",
    "    df_matched_m_all1 = df_matched_m_all[[\n",
    "        \"crop_cy\", \"crop_ly\", \"grass_ly\", \"grass_cy\", \"forest_ly\", \"forest_cy\", \n",
    "        \"crop_npp_cy\", \"crop_npp_ly\", \"grass_npp_ly\", \"grass_npp_cy\", \"forest_npp_ly\", \"forest_npp_cy\", \n",
    "        \"country\", \"year\", \"ratio\"\n",
    "    ]].copy()\\\n",
    "        .assign(crop_change=df_matched_m_all[\"crop_change\"] - df_matched_m_all[\"crop_change_n\"])\\\n",
    "        .assign(crop_npp_change=df_matched_m_all[\"crop_npp_change\"] - df_matched_m_all[\"crop_npp_change_n\"])\\\n",
    "        .assign(forest_change=df_matched_m_all[\"forest_change\"] - df_matched_m_all[\"forest_change_n\"])\\\n",
    "        .assign(forest_npp_change=df_matched_m_all[\"forest_npp_change\"] - df_matched_m_all[\"forest_npp_change_n\"])\\\n",
    "        .assign(grass_change=df_matched_m_all[\"grass_change\"] - df_matched_m_all[\"grass_change_n\"])\\\n",
    "        .assign(grass_npp_change=df_matched_m_all[\"grass_npp_change\"] - df_matched_m_all[\"grass_npp_change_n\"])\\\n",
    "        .reset_index()\\\n",
    "        .merge(df_ttest_class_result, on=[\"year\", \"country\"])\\\n",
    "        .set_index(\"index\")\n",
    "        \n",
    "    df_matched_m_all1_crop_d = df_matched_m_all1.query(\"CPD == True\")\n",
    "    df_matched_m_all1_crop_s = df_matched_m_all1.query(\"CDS == True\")\n",
    "    df_matched_m_all1_forest_d = df_matched_m_all1.query(\"FD == True\")\n",
    "    df_matched_m_all1_forest_s = df_matched_m_all1.query(\"FS == True\")\n",
    "    df_matched_m_all1_grass_d = df_matched_m_all1.query(\"GD == True\")\n",
    "    df_matched_m_all1_grass_s = df_matched_m_all1.query(\"GS == True\")\n",
    "    \n",
    "    degradation_forest_df = df_matched_m_all1_forest_d.query(\"forest_npp_change<0\")\\\n",
    "        .assign(degradation_forest_npp=lambda _df: _df[\"forest_cy\"] * _df[\"forest_npp_change\"] * pixel_area * _df[\"ratio\"])\\\n",
    "        .groupby([\"year\", \"country\"], as_index=False)[\"degradation_forest_npp\"].sum()\\\n",
    "        .set_index([\"year\", \"country\"])\n",
    "    degradation_grass_df = df_matched_m_all1_grass_d.query(\"grass_npp_change<0\")\\\n",
    "        .assign(degradation_grass_npp=lambda _df: _df[\"grass_cy\"] * _df[\"grass_npp_change\"] * pixel_area * _df[\"ratio\"])\\\n",
    "        .groupby([\"year\", \"country\"], as_index=False)[\"degradation_grass_npp\"].sum()\\\n",
    "        .set_index([\"year\", \"country\"])\n",
    "\n",
    "    shrink_forest_df = df_matched_m_all1_forest_s.query(\"forest_change<0\")\\\n",
    "        .assign(shrink_forest_npp=lambda _df: _df[\"forest_change\"] * _df[\"forest_npp_cy\"] * pixel_area * _df[\"ratio\"])\\\n",
    "        .groupby([\"year\", \"country\"], as_index=False)[\"shrink_forest_npp\"].sum()\\\n",
    "        .set_index([\"year\", \"country\"])\n",
    "    shrink_grass_df = df_matched_m_all1_grass_s.query(\"grass_change<0\")\\\n",
    "        .assign(shrink_grass_npp=lambda _df: _df[\"grass_change\"] * _df[\"grass_npp_cy\"] * pixel_area * _df[\"ratio\"])\\\n",
    "        .groupby([\"year\", \"country\"], as_index=False)[\"shrink_grass_npp\"].sum()\\\n",
    "        .set_index([\"year\", \"country\"])\n",
    "        \n",
    "    degradation_crop_df = df_matched_m_all1_crop_d.query(\"crop_npp_change<0\")\\\n",
    "        .assign(degradation_crop_npp=lambda _df: _df[\"crop_cy\"] * _df[\"crop_npp_change\"] * pixel_area * _df[\"ratio\"])\\\n",
    "        .groupby([\"year\", \"country\"], as_index=False)[\"degradation_crop_npp\"].sum()\\\n",
    "        .set_index([\"year\", \"country\"])\n",
    "\n",
    "    abandon_crop_df = df_matched_m_all1_crop_s.query(\"crop_change<0\")\\\n",
    "        .assign(abandon_crop_npp=lambda _df: _df[\"crop_change\"] * _df[\"crop_npp_cy\"] * pixel_area * _df[\"ratio\"])\\\n",
    "        .groupby([\"year\", \"country\"], as_index=False)[\"abandon_crop_npp\"].sum()\\\n",
    "        .set_index([\"year\", \"country\"])\n",
    "        \n",
    "    degradation_vegetation = degradation_forest_df.join(degradation_grass_df, how=\"outer\")\n",
    "    shrink_vegetation = shrink_forest_df.join(shrink_grass_df, how=\"outer\")\n",
    "    loss_vegetation = degradation_vegetation.join(shrink_vegetation, how=\"outer\").fillna(0)\n",
    "    loss_crop_df = degradation_crop_df.join(abandon_crop_df, how=\"outer\")\n",
    "    loss_df = loss_vegetation.join(loss_crop_df, how=\"outer\").fillna(0) * -1\n",
    "    loss_df = loss_df.reset_index().assign(region=lambda _df: _df[\"country\"].map(country_to_region)).set_index([\"year\", \"region\", \"country\"])\n",
    "    return loss_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_diff_m_all, df_matched_m_all = get_df_dif_matched_all(radius)\n",
    "\n",
    "df_voronoi_ratio = pd.read_csv(path_data / f\"PSM/voronoi/{radius}km.csv\", index_col=0)\n",
    "df_matched_m_all = df_matched_m_all.merge(df_voronoi_ratio, on=[\"year\", \"idx\"])\n",
    "\n",
    "loss_df = cal_npp_loss(df_matched_m_all, radius)\n",
    "(path_data / \"PSM_results/loss\").mkdir(exist_ok=True)\n",
    "out_file = path_data / \"PSM_results/loss/NPPw.csv\"\n",
    "loss_df.to_csv(out_file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
