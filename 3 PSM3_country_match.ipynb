{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import *\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from matplotlib.colors import TwoSlopeNorm\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "res_1km = 1 / 12 / 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ar_circle(radius=10):\n",
    "    radius_clip = {3: 2.54, 4:3.53, 5: 4.49, 6: 5.52, 7: 6.52, 8: 7.49, 9: 8.52, 10: 9.49, 11: 10.52, 12: 11.49, 13: 12.49, 14: 13.51, 15: 14.49, 16: 15.52, 17: 16.46, 18: 17.49, 19: 18.49, 20: 19.47, 21: 20.49, 22: 21.49, 23: 22.49, 24: 23.49, 25: 24.43}[radius]\n",
    "    gdf_circle = gpd.GeoDataFrame({}, geometry=gpd.GeoDataFrame({}, geometry=gpd.points_from_xy([0], [0])).buffer(radius_clip), crs=\"epsg:4326\")\n",
    "    da_circle = xr.DataArray(np.ones((radius * 2 + 1, radius * 2 + 1)), coords={\"y\": np.arange(-radius, radius + 1), \"x\": np.arange(-radius, radius + 1)})\\\n",
    "        .rio.write_crs(\"epsg:4326\")\\\n",
    "        .rio.clip(gdf_circle.geometry, all_touched=True, drop=False)\\\n",
    "        .fillna(0).astype(np.uint8)\n",
    "    return da_circle, da_circle.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "st1 = \"\"\"Value\tColor\tDescription\n",
    "1\t#05450a\tEvergreen Needleleaf Forests: dominated by evergreen conifer trees (canopy >2m). Tree cover >60%.\n",
    "2\t#086a10\tEvergreen Broadleaf Forests: dominated by evergreen broadleaf and palmate trees (canopy >2m). Tree cover >60%.\n",
    "3\t#54a708\tDeciduous Needleleaf Forests: dominated by deciduous needleleaf (larch) trees (canopy >2m). Tree cover >60%.\n",
    "4\t#78d203\tDeciduous Broadleaf Forests: dominated by deciduous broadleaf trees (canopy >2m). Tree cover >60%.\n",
    "5\t#009900\tMixed Forests: dominated by neither deciduous nor evergreen (40-60% of each) tree type (canopy >2m). Tree cover >60%.\n",
    "6\t#c6b044\tClosed Shrublands: dominated by woody perennials (1-2m height) >60% cover.\n",
    "7\t#dcd159\tOpen Shrublands: dominated by woody perennials (1-2m height) 10-60% cover.\n",
    "8\t#dade48\tWoody Savannas: tree cover 30-60% (canopy >2m).\n",
    "9\t#fbff13\tSavannas: tree cover 10-30% (canopy >2m).\n",
    "10\t#b6ff05\tGrasslands: dominated by herbaceous annuals (<2m).\n",
    "11\t#27ff87\tPermanent Wetlands: permanently inundated lands with 30-60% water cover and >10% vegetated cover.\n",
    "12\t#c24f44\tCroplands: at least 60% of area is cultivated cropland.\n",
    "13\t#a5a5a5\tUrban and Built-up Lands: at least 30% impervious surface area including building materials, asphalt and vehicles.\n",
    "14\t#ff6d4c\tCropland/Natural Vegetation Mosaics: mosaics of small-scale cultivation 40-60% with natural tree, shrub, or herbaceous vegetation.\n",
    "15\t#69fff8\tPermanent Snow and Ice: at least 60% of area is covered by snow and ice for at least 10 months of the year.\n",
    "16\t#f9ffa4\tBarren: at least 60% of area is non-vegetated barren (sand, rock, soil) areas with less than 10% vegetation.\n",
    "17\t#1c0dff\tWater Bodies: at least 60% of area is covered by permanent water bodies.\"\"\"\n",
    "\n",
    "class_table = pd.read_csv(StringIO(st1), sep=\"\\t\")\n",
    "class_table[\"Value\"] = class_table[\"Value\"].astype(int)\n",
    "class_table[\"luc\"] = class_table[\"Description\"].str.split(\":\", expand=True)[0]\n",
    "\n",
    "code2color = class_table.set_index(\"Value\")[\"Color\"].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_gdf(year):\n",
    "    gdf_conflict_1year = gpd.read_file(path_data / f\"PSM/sample_point/conflict_{year}.shp\")\n",
    "    gdf_miss_conflict = gpd.read_file(path_data / f\"PSM/sample_point/non_conflict_{year}.shp\")\n",
    "    return gdf_conflict_1year, gdf_miss_conflict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clip_sample(nc_file, da_circle):\n",
    "    da_ = xr.open_dataarray(nc_file)\n",
    "    return xr.where(da_circle==1, da_.sel(x=da_circle.x, y=da_circle.y), np.nan)\n",
    "    \n",
    "def load_point_and_zonal_data(year, radius):\n",
    "    da_circle, ar_circle = get_ar_circle(radius)\n",
    "    gdf_conflict_1year, gdf_miss_conflict = get_sample_gdf(year)\n",
    "    da_conflict_lst = [clip_sample(path_data / f\"PSM20km/conflict_sample/{year}_{name_}.nc\", da_circle) for name_ in [\"luc_lastyear\", \"luc_currentyear\", \"road_dis\", \"boundary_dis\", \"npp_lastyear\", \"npp_currentyear\", \"pop\", \"pop_ly\"]]\n",
    "    da_non_conflict_lst = [clip_sample(path_data / f\"PSM20km/non_conflict_sample/{year}_{name_}.nc\", da_circle) for name_ in [\"luc_lastyear\", \"luc_currentyear\", \"road_dis\", \"boundary_dis\", \"npp_lastyear\", \"npp_currentyear\", \"pop\", \"pop_ly\"]]\n",
    "    return (gdf_conflict_1year, gdf_miss_conflict), (da_conflict_lst, da_non_conflict_lst)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distance to the nearest point\n",
    "from sklearn.neighbors import BallTree\n",
    "\n",
    "def get_nearest(src_points, candidates, k_neighbors=1):\n",
    "    tree = BallTree(candidates, leaf_size=15, metric='haversine')\n",
    "    distances, indices = tree.query(src_points, k=k_neighbors)\n",
    "    distances = distances.transpose()\n",
    "    indices = indices.transpose()\n",
    "    closest = indices[0]\n",
    "    closest_dist = distances[0]\n",
    "    return (closest, closest_dist)\n",
    "\n",
    "def nearest_neighbor(left_gdf, right_gdf, return_dist=False):\n",
    "    left_geom_col = left_gdf.geometry.name\n",
    "    right_geom_col = right_gdf.geometry.name\n",
    "    right = right_gdf.copy().reset_index(drop=True)\n",
    "    left_radians = np.array(left_gdf[left_geom_col].apply(lambda geom: (geom.x * np.pi / 180, geom.y * np.pi / 180)).to_list())\n",
    "    right_radians = np.array(right[right_geom_col].apply(lambda geom: (geom.x * np.pi / 180, geom.y * np.pi / 180)).to_list())\n",
    "    closest, dist = get_nearest(src_points=left_radians, candidates=right_radians)\n",
    "    closest_points = right.loc[closest]\n",
    "    closest_points = closest_points.reset_index(drop=True)\n",
    "    if return_dist:\n",
    "        earth_radius = 6371000  # meters\n",
    "        closest_points['distance'] = dist * earth_radius\n",
    "    return closest_points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def zonal_stat_sample(gdf_conflict_1year, da_conflict_lst, gdf_conflict_lastyear):\n",
    "    dis_to_conflict_lastyear = nearest_neighbor(gdf_conflict_1year, gdf_conflict_lastyear, return_dist=True)\n",
    "\n",
    "    (\n",
    "        da_combine_no_coords_lastyear, da_combine_no_coords_1year, \n",
    "        da_combine_no_coords_road_dis, da_combine_no_coords_boundary_dis, \n",
    "        da_combine_no_coords_npp_lastyear, da_combine_no_coords_npp_1year,\n",
    "        da_combine_no_coords_pop, da_combine_no_coords_pop_ly,\n",
    "    ) = da_conflict_lst\n",
    "\n",
    "    total_area_ly = (~np.isnan(da_combine_no_coords_lastyear)).sum(dim=[\"x\", \"y\"])\n",
    "    total_area_cy = (~np.isnan(da_combine_no_coords_1year)).sum(dim=[\"x\", \"y\"])\n",
    "    total_pop = da_combine_no_coords_pop.sum(dim=[\"x\", \"y\"]).values\n",
    "    total_pop_ly = da_combine_no_coords_pop_ly.sum(dim=[\"x\", \"y\"]).values\n",
    "\n",
    "    luc_ratio_ly, luc_ratio_cy = {}, {}\n",
    "    for year_lc, da_lc in zip([\"ly\", \"cy\"], [da_combine_no_coords_lastyear, da_combine_no_coords_1year]):\n",
    "        for luc_, luc_name in [\n",
    "            [[12, 14], f\"crop_{year_lc}\"], \n",
    "            [[13], f\"built_{year_lc}\"],\n",
    "            [[1, 2, 3, 4, 5],  f\"forest_{year_lc}\"],\n",
    "            [[6, 7], f\"shrubland_{year_lc}\"],\n",
    "            [[10],  f\"grass_{year_lc}\"],\n",
    "        ]:\n",
    "            if year_lc == \"ly\":\n",
    "                luc_ratio_ly[luc_name] = ((da_lc.isin(luc_)).sum(dim=[\"x\", \"y\"]) / total_area_ly).values\n",
    "            elif year_lc == \"cy\":\n",
    "                luc_ratio_cy[luc_name] = ((da_lc.isin(luc_)).sum(dim=[\"x\", \"y\"]) / total_area_cy).values\n",
    "\n",
    "    gdf_conflict_1year_zonal = gdf_conflict_1year.copy()\\\n",
    "        .assign(pop=total_pop)\\\n",
    "        .assign(pop_ly=total_pop_ly)\\\n",
    "        .assign(pop_change=total_pop-total_pop_ly)\\\n",
    "        .assign(dis_c_ly=dis_to_conflict_lastyear[\"distance\"])\\\n",
    "        .assign(crop_ly=luc_ratio_ly[\"crop_ly\"]).assign(crop_cy=luc_ratio_cy[\"crop_cy\"])\\\n",
    "        .assign(crop_change=lambda _df: _df[\"crop_cy\"] - _df[\"crop_ly\"])\\\n",
    "        .assign(forest_ly=luc_ratio_ly[\"forest_ly\"]).assign(forest_cy=luc_ratio_cy[\"forest_cy\"])\\\n",
    "        .assign(forest_change=lambda _df: _df[\"forest_cy\"] - _df[\"forest_ly\"])\\\n",
    "        .assign(grass_ly=luc_ratio_ly[\"grass_ly\"]).assign(grass_cy=luc_ratio_cy[\"grass_cy\"])\\\n",
    "        .assign(grass_change=lambda _df: _df[\"grass_cy\"] - _df[\"grass_ly\"])\\\n",
    "        .assign(shrubland_ly=luc_ratio_ly[\"shrubland_ly\"]).assign(shrubland_cy=luc_ratio_cy[\"shrubland_cy\"])\\\n",
    "        .assign(shrubland_change=lambda _df: _df[\"shrubland_cy\"] - _df[\"shrubland_ly\"])\\\n",
    "        .assign(built_ly=luc_ratio_ly[\"built_ly\"]).assign(built_cy=luc_ratio_cy[\"built_cy\"])\\\n",
    "        .assign(dis2road=da_combine_no_coords_road_dis.mean(dim=[\"x\", \"y\"]).values)\\\n",
    "        .assign(dis2bound=da_combine_no_coords_boundary_dis.mean(dim=[\"x\", \"y\"]).values)\\\n",
    "        .assign(npp_cy=da_combine_no_coords_npp_1year.mean(dim=[\"x\", \"y\"]).values)\\\n",
    "        .assign(crop_npp_ly=xr.where(da_combine_no_coords_lastyear == 12, da_combine_no_coords_npp_lastyear, np.nan).mean(dim=[\"x\", \"y\"]).values)\\\n",
    "        .assign(crop_npp_cy=xr.where(da_combine_no_coords_1year == 12, da_combine_no_coords_npp_1year, np.nan).mean(dim=[\"x\", \"y\"]).values)\\\n",
    "        .assign(crop_npp_change=lambda _df: _df[\"crop_npp_cy\"] - _df[\"crop_npp_ly\"])\\\n",
    "        .assign(forest_npp_ly=xr.where(da_combine_no_coords_lastyear.isin([1, 2, 3, 4, 5]), da_combine_no_coords_npp_lastyear, np.nan).mean(dim=[\"x\", \"y\"]).values)\\\n",
    "        .assign(forest_npp_cy=xr.where(da_combine_no_coords_1year.isin([1, 2, 3, 4, 5]), da_combine_no_coords_npp_1year, np.nan).mean(dim=[\"x\", \"y\"]).values)\\\n",
    "        .assign(forest_npp_change=lambda _df: _df[\"forest_npp_cy\"] - _df[\"forest_npp_ly\"])\\\n",
    "        .assign(grass_npp_ly=xr.where(da_combine_no_coords_lastyear.isin([10]), da_combine_no_coords_npp_lastyear, np.nan).mean(dim=[\"x\", \"y\"]).values)\\\n",
    "        .assign(grass_npp_cy=xr.where(da_combine_no_coords_1year.isin([10]), da_combine_no_coords_npp_1year, np.nan).mean(dim=[\"x\", \"y\"]).values)\\\n",
    "        .assign(grass_npp_change=lambda _df: _df[\"grass_npp_cy\"] - _df[\"grass_npp_ly\"])\\\n",
    "\n",
    "    return gdf_conflict_1year_zonal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sel_sample_1country(gdf_conflict_1year_zonal, gdf_non_conflict_1year_zonal, sel_country):\n",
    "    gdf_conflict_clip = gdf_conflict_1year_zonal.clip(gdf_world.query('name_long == @sel_country'))\n",
    "    gdf_non_conflict_clip = gdf_non_conflict_1year_zonal.clip(gdf_world.query('name_long == @sel_country').buffer(res_1km*100))\n",
    "    # df_sample = pd.concat([gdf_conflict_clip, gdf_non_conflict_clip]).query(\"crop_cy > 0\").reset_index(drop=True)\n",
    "    df_sample_sel = pd.concat([gdf_conflict_clip, gdf_non_conflict_clip]).reset_index(drop=True)\n",
    "    return df_sample_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_conflict_to_non_con(df_sample):\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(df_sample[['pop', 'dis_c_ly', 'crop_ly', 'built_ly', 'dis2road', 'dis2bound']])\n",
    "    logistic_model = LogisticRegression(solver='liblinear', random_state=0)\n",
    "    logistic_model.fit(X_scaled, df_sample['c'])\n",
    "    propensity_scores = logistic_model.predict_proba(X_scaled)[:, 1]\n",
    "\n",
    "    df_sample = df_sample.assign(ps=propensity_scores)\n",
    "    df_c_match = df_sample.query('c == 1')\n",
    "\n",
    "    nn = NearestNeighbors(n_neighbors=1, metric='euclidean')\n",
    "    nn.fit(propensity_scores[df_sample['c'] == 0].reshape(-1, 1)) \n",
    "\n",
    "    matched_indices = []\n",
    "    for idx in df_sample.query('c == 1').index:\n",
    "        treated_score = propensity_scores[idx]\n",
    "        nearest_idx = nn.kneighbors([[treated_score]])[1][0][0]\n",
    "        matched_indices.append(df_sample[df_sample['c'] == 0].index[nearest_idx])\n",
    "\n",
    "    matched_df = df_sample.loc[matched_indices]\n",
    "    df_matched = df_c_match.reset_index(drop=True).join(matched_df.reset_index(drop=True), rsuffix=\"_n\")\n",
    "    return df_matched"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_diff_from_matched(df_matched, sel_country, year):\n",
    "    diff_col = ['pop', 'crop_change', 'forest_change', 'grass_change', 'crop_npp_change', 'forest_npp_change', 'grass_npp_change']\n",
    "    diff_data = {}\n",
    "    keep_cols = [\"x\", \"y\"]\n",
    "    for col_ in keep_cols:\n",
    "        diff_data[col_] = df_matched[col_]\n",
    "    for col_ in diff_col:\n",
    "        diff_data[col_] = df_matched[col_] - df_matched[f\"{col_}_n\"]\n",
    "    df_diff = pd.DataFrame(diff_data)\n",
    "    df_diff = df_diff.assign(country=sel_country).assign(year=year)\n",
    "    return df_diff\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pipline 1year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipline_1year(year, radius):\n",
    "    (gdf_conflict_1year, gdf_miss_conflict), (da_conflict_lst, da_non_conflict_lst) = load_point_and_zonal_data(year, radius)\n",
    "    gdf_conflict_lastyear = gpd.read_file(path_data / f\"PSM/sample_point/conflict_{year-1}.shp\")\n",
    "    \n",
    "    gdf_conflict_1year_zonal = zonal_stat_sample(gdf_conflict_1year, da_conflict_lst, gdf_conflict_lastyear).assign(c=1)\n",
    "    gdf_non_conflict_1year_zonal = zonal_stat_sample(gdf_miss_conflict, da_non_conflict_lst, gdf_conflict_lastyear).assign(c=0)\n",
    "\n",
    "    # select 90% conflict countries\n",
    "    df_conflict_count = gpd.sjoin(gdf_conflict_1year_zonal, gdf_world[['name_long', \"geometry\"]]).groupby(\"name_long\")[\"idx\"].count().sort_values(ascending=False)\n",
    "    count_all = df_conflict_count.sum()\n",
    "    sel_countries = df_conflict_count[(df_conflict_count.cumsum() / count_all) < 0.9].index\n",
    "\n",
    "    diff_data = []\n",
    "    matched_data = []\n",
    "    for sel_country in sel_countries:\n",
    "        df_sample = sel_sample_1country(gdf_conflict_1year_zonal, gdf_non_conflict_1year_zonal, sel_country)\n",
    "        df_matched = match_conflict_to_non_con(df_sample).assign(country=sel_country).assign(year=year)\n",
    "        df_diff = cal_diff_from_matched(df_matched, sel_country, year)\n",
    "        diff_data.append(df_diff)\n",
    "        matched_data.append(df_matched)\n",
    "\n",
    "    df_matched_m = pd.concat(matched_data).reset_index(drop=True)\n",
    "    df_diff_m = pd.concat(diff_data).reset_index(drop=True)\n",
    "    \n",
    "    return df_matched_m, df_diff_m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "radius = 10\n",
    "for year in range(2002, 2023):\n",
    "    if not (path_data / f\"PSM_results/diff/{radius}km_{year}.csv\").exists():\n",
    "        df_matched_m, df_diff_m = pipline_1year(year, radius)\n",
    "        (path_data / f\"PSM_results/matched\").mkdir(parents=True, exist_ok=True)\n",
    "        (path_data / f\"PSM_results/diff\").mkdir(parents=True, exist_ok=True)\n",
    "        \n",
    "        df_matched_m.to_csv(path_data / f\"PSM_results/matched/{radius}km_{year}.csv\")\n",
    "        df_diff_m.to_csv(path_data / f\"PSM_results/diff/{radius}km_{year}.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pyg1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
